{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.microsoft.com/en-us/learn/paths/build-ai-solutions-with-azure-ml-service/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://thenewstack.io/build-and-deploy-a-machine-learning-model-with-azure-ml-service/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.precision',3)\n",
    "from sklearn.externals import joblib\n",
    " \n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from azureml.core import Workspace, Experiment, Run\n",
    "\n",
    "import math, random, pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = Workspace.from_config(aml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ws = Workspace.create(name='aml',\n",
    "#                       subscription_id='xxxxxxxxxxxxxxxxxxxxxxxxxx', \n",
    "#                       resource_group='ts_test',\n",
    "#                       create_resource_group = True,\n",
    "#                       location='southeastasia'\n",
    "#                      )\n",
    "\n",
    "\n",
    "ws = Workspace.get(name='aml',\n",
    "                      subscription_id='xxxxxxxxxxxxxxxxxxxxxxxxxx', \n",
    "                      resource_group='ts_test',\n",
    "#                       create_resource_group = True,\n",
    "#                       location='southeastasia'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core import Workspace, Experiment, Run\n",
    "# import math, random, pickle, json\n",
    "\n",
    "\n",
    "exp = Experiment(workspace = ws, name='ts')\n",
    "run = exp.start_logging()                   \n",
    "run.log(\"Experiment start time\", str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "###############SQL Alchemy for data uploading#################\n",
    "from sqlalchemy import create_engine \n",
    "import urllib\n",
    "server = 'TE\\SQL2016'\n",
    "database = 'ABC'\n",
    "username = 'sa'\n",
    "password = 'sa'\n",
    "#driver='{ODBC Driver 17 for SQL Server}'\n",
    "#Enabled = 'Enabled'\n",
    "params = urllib.parse.quote_plus(\n",
    "'DRIVER={ODBC Driver 17 for SQL Server};'+ \n",
    "'SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password) \n",
    "\n",
    "engine = create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params) \n",
    "\n",
    "###Connection checking\n",
    "connected = pd.io.sql._is_sqlalchemy_connectable(engine)\n",
    "print (connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_is = pd.read_csv('D:\\.csv', parse_dates=['Date'],dayfirst=True)\n",
    "is_df = df_is.sort_values(['year', 'month'], ascending=[True, True])\n",
    "\n",
    "is_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_df['Amount'] = is_df['Amount'].abs()\n",
    "is_df = is_df.loc[(is_df['Session Code'].isin(['Operating Expenses'])) & (is_df['Book'].isin(['Accrual']))]\n",
    "is_df = is_df.groupby(['pro Name','Date']).agg({'Amount':sum}).reset_index()\n",
    "\n",
    "df_exp = is_df #.loc[is_df['Amount'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_exp.loc[df_exp['Amount'] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tedf = df_exp.loc[(df_exp['pro Name'] == 'xyz')]\n",
    "tedf['Amount'].iloc[tedf.index == '2019-11-01'] = 0\n",
    "tedf = tedf['Amount']\n",
    "tedf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_smoothing_configs(seasonal=[None]):\n",
    "    models = list()\n",
    "    # define config lists\n",
    "    t_params = ['add', 'mul', None]\n",
    "    d_params = [True, False]\n",
    "    s_params = ['add', 'mul', None]\n",
    "    p_params = seasonal\n",
    "    b_params = [True, False]\n",
    "    r_params = [True, False]\n",
    "    # create config instances\n",
    "    for t in t_params:\n",
    "        for d in d_params:\n",
    "            for s in s_params:\n",
    "                for p in p_params:\n",
    "                    for b in b_params:\n",
    "                        for r in r_params:\n",
    "                            cfg = [t,d,s,p,b,r]\n",
    "                            models.append(cfg)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_list = exp_smoothing_configs(seasonal=[12])\n",
    "# cfg_list = exp_smoothing_configs(seasonal=[0,6,12])\n",
    "len(cfg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_smoothing_forecast(data, config):\n",
    "    t,d,s,p,b,r = config\n",
    "    train = data[:'2018'].copy()\n",
    "    test = data['2019-01-01':'2019-10-01'].copy()\n",
    "    # define model\n",
    "    if (t == None):\n",
    "        model = ExponentialSmoothing(train, trend=t, seasonal=s, seasonal_periods=p)\n",
    "    else:\n",
    "        model = ExponentialSmoothing(train, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "    # fit model\n",
    "    model_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "    # make one step forecast\n",
    "    y_forecast = model_fit.forecast(10)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(test,y_forecast))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df_exp['pro Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holt's Winter Model\n",
      "0\n",
      "['add', True, 'add', 12, True, True]\n",
      "Error\n",
      "1\n",
      "['add', True, 'add', 12, True, False]\n",
      "Error\n",
      "2\n",
      "['add', True, 'add', 12, False, True]\n",
      "305470.7094210574\n",
      "3\n",
      "['add', True, 'add', 12, False, False]\n",
      "292545.1927775726\n",
      "4\n",
      "['add', True, 'mul', 12, True, True]\n",
      "Error\n",
      "5\n",
      "['add', True, 'mul', 12, True, False]\n",
      "Error\n",
      "6\n",
      "['add', True, 'mul', 12, False, True]\n",
      "316944.8660490859\n",
      "7\n",
      "['add', True, 'mul', 12, False, False]\n",
      "304819.502671156\n",
      "8\n",
      "['add', True, None, 12, True, True]\n",
      "Error\n",
      "9\n",
      "['add', True, None, 12, True, False]\n",
      "Error\n",
      "10\n",
      "['add', True, None, 12, False, True]\n",
      "182679.5297555348\n",
      "11\n",
      "['add', True, None, 12, False, False]\n",
      "183746.63005922126\n",
      "12\n",
      "['add', False, 'add', 12, True, True]\n",
      "Error\n",
      "13\n",
      "['add', False, 'add', 12, True, False]\n",
      "Error\n",
      "14\n",
      "['add', False, 'add', 12, False, True]\n",
      "305470.7094210574\n",
      "15\n",
      "['add', False, 'add', 12, False, False]\n",
      "292545.1927775726\n",
      "16\n",
      "['add', False, 'mul', 12, True, True]\n",
      "Error\n",
      "17\n",
      "['add', False, 'mul', 12, True, False]\n",
      "Error\n",
      "18\n",
      "['add', False, 'mul', 12, False, True]\n",
      "316930.343901092\n",
      "19\n",
      "['add', False, 'mul', 12, False, False]\n",
      "304805.95591367775\n",
      "20\n",
      "['add', False, None, 12, True, True]\n",
      "Error\n",
      "21\n",
      "['add', False, None, 12, True, False]\n",
      "Error\n",
      "22\n",
      "['add', False, None, 12, False, True]\n",
      "272470.1493355239\n",
      "23\n",
      "['add', False, None, 12, False, False]\n",
      "264719.3539702896\n",
      "24\n",
      "['mul', True, 'add', 12, True, True]\n",
      "Error\n",
      "25\n",
      "['mul', True, 'add', 12, True, False]\n",
      "Error\n",
      "26\n",
      "['mul', True, 'add', 12, False, True]\n",
      "373613.00784373644\n",
      "27\n",
      "['mul', True, 'add', 12, False, False]\n",
      "361042.16263440315\n",
      "28\n",
      "['mul', True, 'mul', 12, True, True]\n",
      "Error\n",
      "29\n",
      "['mul', True, 'mul', 12, True, False]\n",
      "Error\n",
      "30\n",
      "['mul', True, 'mul', 12, False, True]\n",
      "288136.2856734503\n",
      "31\n",
      "['mul', True, 'mul', 12, False, False]\n",
      "274280.13489089144\n",
      "32\n",
      "['mul', True, None, 12, True, True]\n",
      "Error\n",
      "33\n",
      "['mul', True, None, 12, True, False]\n",
      "Error\n",
      "34\n",
      "['mul', True, None, 12, False, True]\n",
      "232544.26130759122\n",
      "35\n",
      "['mul', True, None, 12, False, False]\n",
      "216639.91154482975\n",
      "36\n",
      "['mul', False, 'add', 12, True, True]\n",
      "Error\n",
      "37\n",
      "['mul', False, 'add', 12, True, False]\n",
      "Error\n",
      "38\n",
      "['mul', False, 'add', 12, False, True]\n",
      "7173543.797176693\n",
      "39\n",
      "['mul', False, 'add', 12, False, False]\n",
      "7393880.2660792805\n",
      "40\n",
      "['mul', False, 'mul', 12, True, True]\n",
      "Error\n",
      "41\n",
      "['mul', False, 'mul', 12, True, False]\n",
      "Error\n",
      "42\n",
      "['mul', False, 'mul', 12, False, True]\n",
      "5666613.2304106215\n",
      "43\n",
      "['mul', False, 'mul', 12, False, False]\n",
      "7552264.7915227385\n",
      "44\n",
      "['mul', False, None, 12, True, True]\n",
      "Error\n",
      "45\n",
      "['mul', False, None, 12, True, False]\n",
      "Error\n",
      "46\n",
      "['mul', False, None, 12, False, True]\n",
      "216411.05932936887\n",
      "47\n",
      "['mul', False, None, 12, False, False]\n",
      "228476.2389289535\n",
      "48\n",
      "[None, True, 'add', 12, True, True]\n",
      "Error\n",
      "49\n",
      "[None, True, 'add', 12, True, False]\n",
      "Error\n",
      "50\n",
      "[None, True, 'add', 12, False, True]\n",
      "247509.90825867918\n",
      "51\n",
      "[None, True, 'add', 12, False, False]\n",
      "243194.38603183292\n",
      "52\n",
      "[None, True, 'mul', 12, True, True]\n",
      "Error\n",
      "53\n",
      "[None, True, 'mul', 12, True, False]\n",
      "Error\n",
      "54\n",
      "[None, True, 'mul', 12, False, True]\n",
      "263562.0424523472\n",
      "55\n",
      "[None, True, 'mul', 12, False, False]\n",
      "252970.22464218587\n",
      "56\n",
      "[None, True, None, 12, True, True]\n",
      "Error\n",
      "57\n",
      "[None, True, None, 12, True, False]\n",
      "Error\n",
      "58\n",
      "[None, True, None, 12, False, True]\n",
      "233200.2590849287\n",
      "59\n",
      "[None, True, None, 12, False, False]\n",
      "216525.14167961245\n",
      "60\n",
      "[None, False, 'add', 12, True, True]\n",
      "Error\n",
      "61\n",
      "[None, False, 'add', 12, True, False]\n",
      "Error\n",
      "62\n",
      "[None, False, 'add', 12, False, True]\n",
      "247509.90825867918\n",
      "63\n",
      "[None, False, 'add', 12, False, False]\n",
      "243194.38603183292\n",
      "64\n",
      "[None, False, 'mul', 12, True, True]\n",
      "Error\n",
      "65\n",
      "[None, False, 'mul', 12, True, False]\n",
      "Error\n",
      "66\n",
      "[None, False, 'mul', 12, False, True]\n",
      "263562.0424523472\n",
      "67\n",
      "[None, False, 'mul', 12, False, False]\n",
      "252970.22464218587\n",
      "68\n",
      "[None, False, None, 12, True, True]\n",
      "Error\n",
      "69\n",
      "[None, False, None, 12, True, False]\n",
      "Error\n",
      "70\n",
      "[None, False, None, 12, False, True]\n",
      "233200.2590849287\n",
      "71\n",
      "[None, False, None, 12, False, False]\n",
      "216525.14167961245\n",
      "182679.5297555348 ['add', True, None, 12, False, True]\n"
     ]
    }
   ],
   "source": [
    "edf = df_exp['Amount'].loc[(df_exp['pro Name'] == 'abc')]\n",
    "edf = edf.groupby(['Date']).agg({'Amount':sum})\n",
    "edf = edf['Amount']\n",
    "ts = edf[:'2018'].copy()\n",
    "ts_v = edf['2019-01-01':'2019-10-01'].copy()\n",
    "ts1  = edf['2014-01-01':'2019-10-01'].copy()\n",
    "#     ind = edf.index[-12:]  # this will select last 12 months' indexes\n",
    "\n",
    "print(\"Holt's Winter Model\")\n",
    "\n",
    "best_RMSE = np.inf\n",
    "best_config = []\n",
    "t1 = d1 = s1 = p1 = b1 = r1 = ''\n",
    "for j in range(len(cfg_list)):\n",
    "    print(j)\n",
    "    try:\n",
    "        cg = cfg_list[j]\n",
    "        print(cg)\n",
    "        rmse = exp_smoothing_forecast(edf, cg)\n",
    "        print(rmse)\n",
    "        if rmse < best_RMSE:\n",
    "            best_RMSE = rmse\n",
    "            best_config = cfg_list[j]\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "        continue\n",
    "\n",
    "print(best_RMSE, best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n"
     ]
    }
   ],
   "source": [
    "t1,d1,s1,p1,b1,r1 = best_config\n",
    "\n",
    "if t1 == None:\n",
    "    hw_model1 = ExponentialSmoothing(ts1, trend=t1, seasonal=s1, seasonal_periods=p1) #ts\n",
    "else:\n",
    "    hw_model1 = ExponentialSmoothing(ts1, trend=t1, seasonal=s1, seasonal_periods=p1, damped=d1) #ts\n",
    "fit2 = hw_model1.fit(optimized=True, use_boxcox=b1, remove_bias=r1)\n",
    "\n",
    "pred_HW = fit2.predict(start=pd.to_datetime('2019-01-01'), end = pd.to_datetime('2019-10-01'))\n",
    "# pred_HW = fit2.predict(start=pd.to_datetime('2019-01-01'), end = pd.to_datetime('2019-12-01'))\n",
    "pred_HW = pd.Series(data=pred_HW)\n",
    "df_exp_pred = pd.concat([df_exp.loc[(df_exp['pro Name'] == 'abc')], pred_HW.rename('pred_HW')], axis=1)\n",
    "# pred_data.append(df_exp_pred)\n",
    "#     print(model_eval(y_truth, pred_6_HW))\n",
    "print('-*-'*20)\n",
    "\n",
    "# 143654.42930094403 [None, True, 'add', 12, False, True]\n",
    "# 162996.80021279448 [None, True, 'add', 12, False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit2.forecast(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1788323.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(1.788323e+06)\n",
    "\n",
    "# df_exp_pred['pred_HW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(y, predictions):\n",
    "    \n",
    "    # Import library for metrics\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "    # Mean absolute error (MAE)\n",
    "    mae = mean_absolute_error(y, predictions)\n",
    "\n",
    "    # Mean squared error (MSE)\n",
    "    mse = mean_squared_error(y, predictions)\n",
    "\n",
    "    \n",
    "    # SMAPE is an alternative for MAPE when there are zeros in the testing data. It\n",
    "    # scales the absolute percentage by the sum of forecast and observed values\n",
    "    SMAPE = np.mean(np.abs((y - predictions) / ((y + predictions)/2))) * 100\n",
    "\n",
    "\n",
    "    # Calculate the Root Mean Squared Error\n",
    "    rmse = np.sqrt(mean_squared_error(y, predictions))\n",
    "    \n",
    "    # Calculate the Mean Absolute Percentage Error\n",
    "    #     y, predictions = check_array(y, predictions)\n",
    "    MAPE = np.mean(np.abs((y - predictions) / y)) * 100\n",
    "    \n",
    "    #     mean_forecast_error\n",
    "    mfe = np.mean(y - predictions)\n",
    "    \n",
    "    # NMSE normalizes the obtained MSE after dividing it by the test variance. It\n",
    "    # is a balanced error measure and is very effective in judging forecast\n",
    "    # accuracy of a model.\n",
    "\n",
    "    #     normalised_mean_squared_error\n",
    "    NMSE = mse / (np.sum((y - np.mean(y)) ** 2)/(len(y)-1))\n",
    "\n",
    "    \n",
    "    #theil_u_statistic\n",
    "    # It is a normalized measure of total forecast error.\n",
    "    error = y - predictions\n",
    "    mfe = np.sqrt(np.mean(predictions**2))\n",
    "    mse = np.sqrt(np.mean(y**2))\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    theil_u_statistic =  rmse / (mfe*mse)\n",
    "\n",
    "\n",
    "    #     mean_absolute_scaled_error\n",
    "    # This evaluation metric is used to over come some of the problems of MAPE and\n",
    "    # is used to measure if the forecasting model is better than the naive model or\n",
    "    # not.\n",
    "    \n",
    "\n",
    "    # Print metrics\n",
    "    print('Mean Absolute Error:', round(mae, 3))\n",
    "    print('Mean Squared Error:', round(mse, 3))\n",
    "    print('Root Mean Squared Error:', round(rmse, 3))\n",
    "    print('Mean absolute percentage error:', round(MAPE, 3))\n",
    "    print('Scaled Mean absolute percentage error:', round(SMAPE, 3))\n",
    "    print('Mean frequency error:', round(mfe, 3))\n",
    "    print('Normalised mean squared error:', round(NMSE, 3))\n",
    "    print('Theil_u_statistic:', round(theil_u_statistic, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 26694.129\n",
      "Mean Squared Error: 152032.516\n",
      "Root Mean Squared Error: 34972.01\n",
      "Mean absolute percentage error: 21.709\n",
      "Scaled Mean absolute percentage error: 18.707\n",
      "Mean frequency error: 152477.575\n",
      "Normalised mean squared error: 0.843\n",
      "Theil_u_statistic: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "mean_squared_error(ts_v, pred_HW)\n",
    "model_eval(ts_v, pred_HW)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/bdgt_ts_model.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'outputs/bdgt_ts_model.pkl'\n",
    "joblib.dump(fit2, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.log('Intercept :', model.sse)\n",
    "# run.log('Slope :', model.slope[0])\n",
    " \n",
    "run.log(\"Experiment end time\", str(datetime.datetime.now()))\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model bdgt_ts_model\n"
     ]
    }
   ],
   "source": [
    "model = Model.register(model_path = \"outputs/bdgt_ts_model.pkl\",\n",
    "                       model_name = \"bdgt_ts_model\",\n",
    "                       tags = {\"key\": \"1\"},\n",
    "                       description = \"Budget Forecast\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2019-11-01 00:00:00', freq='MS'), Timestamp('2019-12-01 00:00:00', freq='MS'), Timestamp('2020-01-01 00:00:00', freq='MS'), Timestamp('2020-02-01 00:00:00', freq='MS'), Timestamp('2020-03-01 00:00:00', freq='MS'), Timestamp('2020-04-01 00:00:00', freq='MS')]\n"
     ]
    }
   ],
   "source": [
    "filename = 'outputs/bdgt_ts_model.pkl'\n",
    "loaded_model = joblib.load(filename)\n",
    "data = [['2019-01-01', '2019-12-01']]\n",
    "y = loaded_model.forecast(6)#predict(start = data[0][0], end = data[0][1])\n",
    "print(list(y.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y.index.values)\n",
    "d = list(y.index.strftime('%Y-%m-%d').values)\n",
    "a = list(y.values)\n",
    "dict(zip(d,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_portal_url())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsenv = CondaDependencies()\n",
    "tsenv.add_conda_package(\"scikit-learn\")\n",
    "tsenv.add_conda_package(\"matplotlib\")\n",
    "tsenv.add_conda_package(\"statsmodels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "- matplotlib\n",
      "- statsmodels\n",
      "channels:\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"tsenv.yml\",\"w\") as f:\n",
    "    f.write(tsenv.serialize_to_string())\n",
    "with open(\"tsenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1574552.8215747683, 1574539.64301587, 1574538.2557991436, 1574538.1097763304, 1574538.094405508, 1574538.0927875265]'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# np.array(json.loads([['42']]))\n",
    "\n",
    "json.dumps(y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    " \n",
    "import json\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    " \n",
    "from azureml.core.model import Model\n",
    " \n",
    "def init():\n",
    "    global model\n",
    "    # retrieve the path to the model file using the model name\n",
    "    model_path = Model.get_model_path('bdgt_ts_model')\n",
    "    model = joblib.load(model_path)\n",
    " \n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    print(data)\n",
    "    # make prediction\n",
    "    predi = model.forecast(data)\n",
    "    d = list(predi.index.strftime('%Y-%m-%d').values)\n",
    "    a = list(predi.values)\n",
    "    dd = dict(zip(d,a))\n",
    "    return json.dumps(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 999 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    " \n",
    "image_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n",
    "                                                  runtime=\"python\", \n",
    "                                                  conda_file=\"tsenv.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"aml\",  \"method\" : \"ts\"}, \n",
    "                                               description='Budget Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running.....................................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image budget-ts-forecast-125-park2:1, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "service = Webservice.deploy_from_model(workspace = ws,\n",
    "                                       name = 'budget-ts-forecast-125-park2',\n",
    "                                       deployment_config = aciconfig,\n",
    "                                       models = [model],\n",
    "                                       image_config = image_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running......................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -X POST -H 'Content-Type':'application/json' -d '{data:[['1960-01-01', '1960-12-01']]}' http://xxxxxxxxxxxxxxxxxxxx.southeastasia.azurecontainer.io/score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in the browser\n",
    "\n",
    "# http://xxxxxxxxxxxxxxxxxxxxxxxxxxxx.southeastasia.azurecontainer.io/score?data=[[45]]\n",
    "\n",
    "\n",
    "# Output: \n",
    "    \n",
    "# \"[185924.79674796748]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#!flask/bin/python\n",
    "from flask import Flask, jsonify\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "filename = 'model/sal_model.pkl'\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return \"Stackoverflow Salary Predictor\"\n",
    "\n",
    "@app.route('/sal/<int:x>', methods=['GET'])\n",
    "def predict(x):\n",
    "    loaded_model=joblib.load(filename)\n",
    "    y=loaded_model.predict([[x]])[0]\n",
    "    sal=jsonify({'salary': round(y,2)})\n",
    "    return sal\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Run\n",
    "import math, random, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-04-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import dateutil.relativedelta\n",
    "\n",
    "d = datetime.datetime.strptime(\"2013-05-01\", \"%Y-%m-%d\")\n",
    "d2 = d - dateutil.relativedelta.relativedelta(months=1)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python365jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.6.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}